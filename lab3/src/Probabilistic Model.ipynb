{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "# get sentences parsed as trees\n",
    "tree_sents = treebank.parsed_sents()\n",
    "\n",
    "# split sentences into training and testing datasets\n",
    "train_ratio = 0.9\n",
    "train_size = int(len(tree_sents) * train_ratio)\n",
    "tree_sents_train, tree_sents_test = tree_sents[:train_size], tree_sents[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# functions for filtering NP subtrees which are non-recursive\n",
    "# check if exist a child that has the specific label\n",
    "def child_has_label(t, label):\n",
    "    for child in t:\n",
    "        if label == child.label():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# check if tree is NP and no direct child is NP (non recursive NP)\n",
    "nonrec_np = lambda t : t.label() == 'NP' and not child_has_label(t, 'NP')\n",
    "# filter non-recursive NP trees\n",
    "get_nonrec_np_subtrees = lambda tree_sents : [[sub_t for sub_t in t.subtrees(nonrec_np)] for t in tree_sents]\n",
    "\n",
    "# non-recursive NP trees grouped by sentences\n",
    "nonrec_np_subts_train = get_nonrec_np_subtrees(tree_sents_train)\n",
    "nonrec_np_subts_test = get_nonrec_np_subtrees(tree_sents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NP chunks grouped by sentences\n",
    "chunks_train = [[sub_t.leaves() for sub_t in t] for t in nonrec_np_subts_train]\n",
    "chunks_test = [[sub_t.leaves() for sub_t in t] for t in nonrec_np_subts_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#chunks_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the grammar rules, also called productions\n",
    "get_productions = lambda tree_sents : [p for sent in tree_sents for p in sent.productions()]\n",
    "\n",
    "import itertools\n",
    "prods_train = get_productions(itertools.chain(*nonrec_np_subts_train))\n",
    "prods_test  = get_productions(itertools.chain(*nonrec_np_subts_test))\n",
    "\n",
    "# filter non-terminal productions\n",
    "is_non_terminal = lambda p : p.is_nonlexical()\n",
    "prods_train = filter(is_non_terminal, prods_train)\n",
    "prods_test = filter(is_non_terminal, prods_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# production example\n",
    "p = prods_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(NP -> DT NN, 1888),\n",
       " (NP -> -NONE-, 1133),\n",
       " (NP -> NN, 1013),\n",
       " (NP -> NNS, 939),\n",
       " (NP -> NNP, 797),\n",
       " (NP -> NNP NNP, 685),\n",
       " (NP -> DT JJ NN, 682),\n",
       " (NP -> JJ NNS, 605),\n",
       " (NP -> JJ NN, 356),\n",
       " (NP -> DT NNS, 334),\n",
       " (NP -> QP -NONE-, 309),\n",
       " (NP -> CD, 300),\n",
       " (NP -> DT NN NN, 297),\n",
       " (QP -> $ CD CD, 278),\n",
       " (NP -> NN NNS, 272),\n",
       " (NP -> PRP, 262),\n",
       " (NP -> NNP NNP NNP, 259),\n",
       " (NP -> CD NN, 239),\n",
       " (NP -> CD NNS, 232),\n",
       " (NP -> NN NN, 199)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute productions frequency\n",
    "from collections import Counter\n",
    "cnt = Counter(prods_train)\n",
    "\n",
    "# get the 20 most frequent\n",
    "cnt.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute coverage ?\n",
    "unique_prods_train = set(prods_train)\n",
    "unique_prods_test  = set(prods_test)\n",
    "\n",
    "# number of unique productions in testing set covered by training set\n",
    "coverage = 1. * len(unique_prods_train & unique_prods_test) / len(unique_prods_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6942148760330579"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute accuracy ?\n",
    "prods_test_contained_in_train = 0\n",
    "for p in prods_test:\n",
    "    if p in unique_prods_train:\n",
    "        prods_test_contained_in_train += 1\n",
    "\n",
    "# number of productions (including repetitions) in testing set covered by training set\n",
    "accuracy = 1.0 * prods_test_contained_in_train / len(prods_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9422222222222222"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.grammar import CFG, Nonterminal\n",
    "treebank_grammar = CFG(Nonterminal('S'), unique_prods_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#treebank_grammar.productions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.grammar import PCFG, induce_pcfg, Nonterminal\n",
    "treebank_prob_grammar = induce_pcfg(Nonterminal('S'), prods_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#treebank_prob_grammar.productions()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
